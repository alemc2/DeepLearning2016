      -- a typical modern convolution network (conv+relu+pool)
      model = nn.Sequential()

      -- stage 1 : filter bank -> squashing -> L2 pooling -> normalization
      model:add(nn.SpatialConvolutionMM(nfeats, nstates[1], filtsize, filtsize))
      model:add(nn.ReLU())
      model:add(nn.SpatialDropout(0.5))
      model:add(nn.SpatialMaxPooling(poolsize,poolsize,poolsize,poolsize))

      -- stage 2 : filter bank -> squashing -> L2 pooling -> normalization
      model:add(nn.SpatialConvolutionMM(nstates[1], nstates[2], filtsize, filtsize))
      model:add(nn.ReLU())
      model:add(nn.SpatialMaxPooling(poolsize,poolsize,poolsize,poolsize))

      -- stage 3 : standard 2-layer neural network
      model:add(nn.View(nstates[2]*filtsize*filtsize))
      model:add(nn.Linear(nstates[2]*filtsize*filtsize, nstates[3]))
      model:add(nn.ReLU())
      model:add(nn.Linear(nstates[3], noutputs))



==> processing options	
==> switching to CUDA	
==> executing all	
==> downloading dataset	
==> using reduced training data, with part of that as test/validation data	
==> loading dataset	
==> preprocessing data	
==> preprocessing data: normalize globally	
==> verify statistics	
training data mean: -1.5106435531228e-08	
training data standard deviation: 1.0000000156287	
test data mean: 0.012629995727272	
test data standard deviation: 1.0162751665024	
==> visualizing data	
==> define parameters	
==> construct model	
==> here is the model:	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> output]
  (1): nn.SpatialConvolutionMM(1 -> 64, 5x5)
  (2): nn.ReLU
  (3): nn.SpatialDropout(0.500000)
  (4): nn.SpatialMaxPooling(2,2,2,2)
  (5): nn.SpatialConvolutionMM(64 -> 64, 5x5)
  (6): nn.ReLU
  (7): nn.SpatialMaxPooling(2,2,2,2)
  (8): nn.View
  (9): nn.Linear(1600 -> 128)
  (10): nn.ReLU
  (11): nn.Linear(128 -> 10)
}
==> define loss	
==> here is the loss function:	
nn.ClassNLLCriterion
==> defining some tools	
==> configuring optimizer	
==> defining training procedure	
==> defining test procedure	
==> training!	
==> doing epoch on training data:	
==> online epoch # 1 [batchSize = 16]	
 [============================================================ 11985/12000 ===========>.] ETA: 13ms | Step: 0ms         
==> time to learn 1 sample = 0.90819183985392ms	
ConfusionMatrix:
[[    1160       0      15       1       1       7       5       7       8       2]   96.186% 	[class: 1]
 [       2    1288      13      13       5       0       4       9      14       3]   95.337% 	[class: 2]
 [      13      16    1064      30      11       3       7      16      14       2]   90.476% 	[class: 3]
 [      10       6      25    1098       2      32       2      20      22      11]   89.414% 	[class: 4]
 [       8       7       9       7    1078       0      10      14       3      48]   91.047% 	[class: 5]
 [      13       7       5      29       5     929      18      10      25       7]   88.645% 	[class: 6]
 [      21      11       7       1       8      16    1133       6       4       1]   93.791% 	[class: 7]
 [      11       9      15      12      10       3       1    1183       6      29]   92.494% 	[class: 8]
 [      10      25      17      28      10      25      14      12     965      21]   85.626% 	[class: 9]
 [      13       9       5      19      22       7       1      41      13    1063]]  89.103% 	[class: 0]
 + average row correct: 91.211891770363% 
 + average rowUcol correct (VOC measure): 83.984680175781% 
 + global correct: 91.341666666667%
==> saving model to /home/ankit/devel/deeplearning2016/assign1/mnist/results/model.net	
==> testing on test set:	
 [================================================================ 2000/2000 ==========>] Tot: 11s775ms | Step: 0ms     

==> time to test 1 sample = 0.43158793449402ms	
ConfusionMatrix:
[[     198       0       0       0       0       0       1       0       0       0]   99.497% 	[class: 1]
 [       0     220       0       0       0       0       0       0       2       0]   99.099% 	[class: 2]
 [       0       0     183       0       0       0       1       2       5       0]   95.812% 	[class: 3]
 [       0       1       3     218       0       1       0       0       0       3]   96.460% 	[class: 4]
 [       0       1       0       0     178       0       0       1       0       5]   96.216% 	[class: 5]
 [       0       0       0       1       0     176       0       0       0       1]   98.876% 	[class: 6]
 [       1       0       0       0       0       0     184       0       0       0]   99.459% 	[class: 7]
 [       0       0       4       0       0       0       0     197       0       3]   96.569% 	[class: 8]
 [       1       1       2       2       1       3       0       0     191       5]   92.718% 	[class: 9]
 [       0       0       1       0       1       0       0       0       1     201]]  98.529% 	[class: 0]
 + average row correct: 97.32368350029% 
 + average rowUcol correct (VOC measure): 94.818435311317% 
 + global correct: 97.3%
0.9732368350029	
==> found new best model!	
==> increasing patience from 5 to 5	
==> patience: 5	
==> doing epoch on training data:	
==> online epoch # 2 [batchSize = 16]	
 [============================================================ 11985/12000 ===========>.] ETA: 13ms | Step: 0ms         
==> time to learn 1 sample = 0.90454999605815ms	
ConfusionMatrix:
[[    1189       0       1       1       1       1       6       0       5       2]   98.590% 	[class: 1]
 [       0    1326       3       8       2       0       1       4       6       1]   98.150% 	[class: 2]
 [       1       7    1140       8       2       0       0       8       9       1]   96.939% 	[class: 3]
 [       0       2       7    1183       0      13       0      10       6       7]   96.336% 	[class: 4]
 [       0       2       0       0    1159       0       3       3       2      15]   97.889% 	[class: 5]
 [       1       1       1       7       0    1021       7       1       7       2]   97.424% 	[class: 6]
 [       4       1       2       0       1       6    1192       0       2       0]   98.675% 	[class: 7]
 [       0       8       6       7       2       1       0    1240       3      12]   96.951% 	[class: 8]
 [       7       8       7       4       5       6       6       1    1071      12]   95.031% 	[class: 9]
 [       5       0       0       7      20       4       0      12       5    1140]]  95.557% 	[class: 0]
 + average row correct: 97.154107689857% 
 + average rowUcol correct (VOC measure): 94.486131668091% 
 + global correct: 97.175%
==> saving model to /home/ankit/devel/deeplearning2016/assign1/mnist/results/model.net	
==> testing on test set:	
 [================================================================ 2000/2000 ==========>] Tot: 11s748ms | Step: 0ms     

==> time to test 1 sample = 0.43893992900848ms	
ConfusionMatrix:
[[     197       0       0       0       0       0       2       0       0       0]   98.995% 	[class: 1]
 [       0     221       0       0       0       0       0       0       1       0]   99.550% 	[class: 2]
 [       0       0     184       0       1       0       1       2       3       0]   96.335% 	[class: 3]
 [       0       1       5     218       0       1       1       0       0       0]   96.460% 	[class: 4]
 [       0       0       0       0     184       0       0       0       0       1]   99.459% 	[class: 5]
 [       0       0       0       1       0     174       0       0       2       1]   97.753% 	[class: 6]
 [       0       0       0       0       0       0     185       0       0       0]   100.000% 	[class: 7]
 [       0       0       0       0       0       0       0     203       0       1]   99.510% 	[class: 8]
 [       0       0       1       2       0       1       0       0     202       0]   98.058% 	[class: 9]
 [       0       0       1       0       1       0       0       0       3     199]]  97.549% 	[class: 0]
 + average row correct: 98.366912603378% 
 + average rowUcol correct (VOC measure): 96.780235171318% 
 + global correct: 98.35%
0.98366912603378	
==> found new best model!	
==> increasing patience from 5 to 5	
==> patience: 5	
==> doing epoch on training data:	
==> online epoch # 3 [batchSize = 16]	
 [============================================================ 11985/12000 ===========>.] ETA: 13ms | Step: 0ms         
==> time to learn 1 sample = 0.90421259403229ms	
ConfusionMatrix:
[[    1196       0       2       0       1       0       4       0       2       1]   99.171% 	[class: 1]
 [       0    1339       4       1       0       0       0       4       3       0]   99.112% 	[class: 2]
 [       3       5    1153       4       1       0       0       7       2       1]   98.044% 	[class: 3]
 [       1       1       7    1196       0      10       1       5       5       2]   97.394% 	[class: 4]
 [       0       4       0       0    1168       0       1       1       0      10]   98.649% 	[class: 5]
 [       1       0       1       7       0    1024       7       0       5       3]   97.710% 	[class: 6]
 [       3       1       0       0       1       6    1193       0       4       0]   98.758% 	[class: 7]
 [       0       2       5       3       6       0       0    1256       3       4]   98.202% 	[class: 8]
 [       3       2       0       6       3       4       7       5    1093       4]   96.983% 	[class: 9]
 [       3       1       0       2       5       6       0       5       3    1168]]  97.904% 	[class: 0]
 + average row correct: 98.192709684372% 
 + average rowUcol correct (VOC measure): 96.460047960281% 
 + global correct: 98.216666666667%
==> saving model to /home/ankit/devel/deeplearning2016/assign1/mnist/results/model.net	
==> testing on test set:	
 [================================================================ 2000/2000 ==========>] Tot: 11s753ms | Step: 0ms     

==> time to test 1 sample = 0.44384396076202ms	
ConfusionMatrix:
[[     196       0       0       0       0       0       3       0       0       0]   98.492% 	[class: 1]
 [       0     221       0       0       0       1       0       0       0       0]   99.550% 	[class: 2]
 [       0       0     181       0       0       0       1       4       5       0]   94.764% 	[class: 3]
 [       0       0       1     213       0       1       0       4       1       6]   94.248% 	[class: 4]
 [       0       0       0       0     180       0       0       1       0       4]   97.297% 	[class: 5]
 [       0       0       0       1       0     174       1       0       0       2]   97.753% 	[class: 6]
 [       0       0       0       0       0       0     185       0       0       0]   100.000% 	[class: 7]
 [       0       0       0       0       0       0       0     203       0       1]   99.510% 	[class: 8]
 [       0       0       1       2       1       0       0       0     200       2]   97.087% 	[class: 9]
 [       0       0       0       0       0       0       0       0       1     203]]  99.510% 	[class: 0]
 + average row correct: 97.821129560471% 
 + average rowUcol correct (VOC measure): 95.754270553589% 
 + global correct: 97.8%
0.97821129560471	
==> patience: 5	
==> doing epoch on training data:	
==> online epoch # 4 [batchSize = 16]	
 [============================================================ 11985/12000 ===========>.] ETA: 13ms | Step: 0ms         
==> time to learn 1 sample = 0.90576583147049ms	
ConfusionMatrix:
[[    1195       0       0       1       0       0       6       0       1       3]   99.088% 	[class: 1]
 [       0    1340       4       2       0       0       0       2       3       0]   99.186% 	[class: 2]
 [       0       6    1149       6       1       0       1       9       2       2]   97.704% 	[class: 3]
 [       2       1       5    1197       0       8       0       9       3       3]   97.476% 	[class: 4]
 [       0       0       1       0    1169       0       2       1       2       9]   98.733% 	[class: 5]
 [       2       0       1       8       0    1025       7       0       5       0]   97.805% 	[class: 6]
 [       5       0       1       0       1       3    1192       0       6       0]   98.675% 	[class: 7]
 [       0       3       7       5       1       1       0    1251       3       8]   97.811% 	[class: 8]
 [       3       5       3       1       1       3       3       1    1102       5]   97.782% 	[class: 9]
 [       3       2       2       2       5       1       1       5       3    1169]]  97.988% 	[class: 0]
 + average row correct: 98.224806189537% 
 + average rowUcol correct (VOC measure): 96.528034806252% 
 + global correct: 98.241666666667%
==> saving model to /home/ankit/devel/deeplearning2016/assign1/mnist/results/model.net	
==> testing on test set:	
 [================================================================ 2000/2000 ==========>] Tot: 11s771ms | Step: 0ms     

==> time to test 1 sample = 0.44345557689667ms	
ConfusionMatrix:
[[     197       0       0       0       0       0       2       0       0       0]   98.995% 	[class: 1]
 [       0     220       0       0       1       1       0       0       0       0]   99.099% 	[class: 2]
 [       0       0     189       0       1       0       1       0       0       0]   98.953% 	[class: 3]
 [       0       0       2     222       0       2       0       0       0       0]   98.230% 	[class: 4]
 [       0       0       0       0     184       0       0       0       1       0]   99.459% 	[class: 5]
 [       0       0       0       1       0     177       0       0       0       0]   99.438% 	[class: 6]
 [       0       0       0       0       0       2     183       0       0       0]   98.919% 	[class: 7]
 [       0       0       3       0       0       0       0     201       0       0]   98.529% 	[class: 8]
 [       1       1       2       2       0       2       0       0     198       0]   96.117% 	[class: 9]
 [       0       0       0       1       0       3       0       5       4     191]]  93.627% 	[class: 0]
 + average row correct: 98.136699199677% 
 + average rowUcol correct (VOC measure): 96.265464425087% 
 + global correct: 98.1%
0.98136699199677	
==> patience: 5	
==> doing epoch on training data:	
==> online epoch # 5 [batchSize = 16]	
 [============================================================ 11985/12000 ===========>.] ETA: 13ms | Step: 0ms         
==> time to learn 1 sample = 0.90595306952794ms	
ConfusionMatrix:
[[    1197       2       0       1       0       1       2       0       0       3]   99.254% 	[class: 1]
 [       0    1339       4       1       0       0       2       0       4       1]   99.112% 	[class: 2]
 [       1       4    1161       2       1       0       0       5       2       0]   98.724% 	[class: 3]
 [       1       1       2    1212       0       6       0       1       4       1]   98.697% 	[class: 4]
 [       0       1       0       0    1170       0       1       2       0      10]   98.818% 	[class: 5]
 [       1       0       0       6       0    1030       3       1       6       1]   98.282% 	[class: 6]
 [       3       0       0       0       0       4    1198       0       3       0]   99.172% 	[class: 7]
 [       0       2       3       1       3       0       0    1264       1       5]   98.827% 	[class: 8]
 [       1       1       5       1       1       4       2       1    1105       6]   98.048% 	[class: 9]
 [       4       0       0       0       9       3       0       5       3    1169]]  97.988% 	[class: 0]
 + average row correct: 98.692264556885% 
 + average rowUcol correct (VOC measure): 97.420473694801% 
 + global correct: 98.708333333333%
==> saving model to /home/ankit/devel/deeplearning2016/assign1/mnist/results/model.net	
==> testing on test set:	
 [================================================================ 2000/2000 ==========>] Tot: 11s769ms | Step: 0ms     

==> time to test 1 sample = 0.44166958332062ms	
ConfusionMatrix:
[[     196       0       0       0       0       0       3       0       0       0]   98.492% 	[class: 1]
 [       0     222       0       0       0       0       0       0       0       0]   100.000% 	[class: 2]
 [       0       0     187       0       1       0       1       0       2       0]   97.906% 	[class: 3]
 [       0       0       5     218       0       1       1       0       0       1]   96.460% 	[class: 4]
 [       0       0       0       0     184       0       0       0       0       1]   99.459% 	[class: 5]
 [       0       0       0       2       0     173       0       0       2       1]   97.191% 	[class: 6]
 [       0       0       0       0       0       0     185       0       0       0]   100.000% 	[class: 7]
 [       0       0       3       1       0       0       0     199       0       1]   97.549% 	[class: 8]
 [       0       4       2       2       1       0       0       0     196       1]   95.146% 	[class: 9]
 [       2       0       0       0       1       0       0       1       1     199]]  97.549% 	[class: 0]
 + average row correct: 97.975254058838% 
 + average rowUcol correct (VOC measure): 96.021792888641% 
 + global correct: 97.95%
0.97975254058838	
==> out of patience	
==> saving final model to /home/ankit/devel/deeplearning2016/assign1/mnist/results/model.net	

